{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7d9827aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from src.activations import ActivationType, get_activation\n",
    "from src.initialiaztion import get_initialization\n",
    "from src.losses import LossType\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ab7d6884",
   "metadata": {},
   "outputs": [],
   "source": [
    "xavier_initialization = get_initialization(\"xavier\")\n",
    "he_initialization = get_initialization(\"he\")\n",
    "\n",
    "relu = get_activation(\"relu\")[0]\n",
    "sigmoid = get_activation(\"sigmoid\")[0]\n",
    "softmax = get_activation(\"softmax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "47220ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "  def __init__(self, \n",
    "               layer_dims: list[int], \n",
    "               activations: list[ActivationType], \n",
    "               loss_type=LossType, \n",
    "               optimizer_type : str = \"gd\",\n",
    "               seed : int = 42):\n",
    "    self._validate_inputs(layer_dims, activations, loss_type, optimizer_type)\n",
    "    \n",
    "    self.layer_dims = layer_dims\n",
    "    self.activations = activations\n",
    "    self.loss_type = loss_type\n",
    "    self.optimizer_type = optimizer_type\n",
    "    self.seed = seed\n",
    "    self.params = {}\n",
    "    \n",
    "    self._initialize_parameters()\n",
    "    \n",
    "  def forward_pass(self, X: np.ndarray):\n",
    "    # Validation\n",
    "    if self.layer_dims[0] != X.shape[0]:\n",
    "        raise ValueError(\n",
    "            f\"Input dimension mismatch. Expected {self.layer_dims[0]} features, \"\n",
    "            f\"but got {X.shape[0]}.\"\n",
    "        )\n",
    "\n",
    "    L = len(self.layer_dims)\n",
    "    A = X\n",
    "    caches = [] \n",
    "    \n",
    "    print(f\"\\n{'='*15} STARTING FORWARD PASS {'='*15}\")\n",
    "    print(f\"Input Batch Shape: {X.shape} ({X.shape[1]} examples)\")\n",
    "\n",
    "    for i in range(1, L):\n",
    "        act_name = self.activations[i - 1]\n",
    "        act_obj = get_activation(act_name)\n",
    "        \n",
    "        if isinstance(act_obj, tuple):\n",
    "            act_fnc = act_obj[0]\n",
    "        else:\n",
    "            act_fnc = act_obj\n",
    "\n",
    "        W = self.params[f\"W{i}\"]\n",
    "        b = self.params[f\"b{i}\"]\n",
    "        A_prev = A\n",
    "        \n",
    "        Z = np.dot(W, A_prev) + b \n",
    "        A = act_fnc(Z)\n",
    "        \n",
    "        print(f\"\\n--- Layer {i} ({act_name.upper()}) ---\")\n",
    "        print(f\"{'Input Matrix (A_prev)':<25} : {A_prev.shape}\")\n",
    "        print(f\"{'Weight Matrix (W)':<25} : {W.shape}\")\n",
    "        print(f\"{'Bias Vector (b)':<25} : {b.shape} (Broadcasts automatically)\")\n",
    "        print(f\"{'-'*45}\")\n",
    "        print(f\"{'Linear Step (Z = WA+b)':<25} : {Z.shape}\")\n",
    "        print(f\"{'Activation (A = f(Z))':<25} : {A.shape}\")\n",
    "        \n",
    "        caches.append((A_prev, Z))\n",
    "    \n",
    "    print(f\"\\n{'='*15} FORWARD PASS COMPLETE {'='*14}\\n\")\n",
    "    return A, caches\n",
    "    \n",
    "  def _initialize_parameters(self):\n",
    "      np.random.seed(self.seed)\n",
    "      \n",
    "      L = len(self.layer_dims)\n",
    "      \n",
    "      for i in range(1, L):\n",
    "          D_o =  self.layer_dims[i]\n",
    "          D_i = self.layer_dims[i - 1]\n",
    "          act_fnc = self.activations[i - 1]\n",
    "          \n",
    "          if act_fnc == \"relu\":\n",
    "              self.params[f\"W{i}\"] = he_initialization((D_o, D_i))\n",
    "          if act_fnc == \"sigmoid\" or act_fnc == \"softmax\" or act_fnc == \"linear\":\n",
    "              self.params[f\"W{i}\"] = xavier_initialization((D_o, D_i))\n",
    "          \n",
    "          self.params[f\"b{i}\"] = np.zeros((D_o, 1))\n",
    "          \n",
    "  def _validate_inputs(self, layer_dims, activations, loss_type, optimizer_type):\n",
    "    \"\"\"\n",
    "    Private helper to validate all inputs before initialization.\n",
    "    \"\"\"\n",
    "    if not isinstance(layer_dims, list):\n",
    "        raise TypeError(f\"layer_dims must be a list, got {type(layer_dims)}\")\n",
    "    \n",
    "    if not all(isinstance(x, int) for x in layer_dims):\n",
    "        raise TypeError(\"All elements in layer_dims must be integers!\")\n",
    "\n",
    "    if not isinstance(activations, list):\n",
    "          raise TypeError(f\"activations must be a list, got {type(activations)}\")\n",
    "\n",
    "    if len(layer_dims) < 2:\n",
    "        raise ValueError(\"The length of layers must be at least 2 (Input -> Output)\") \n",
    "    \n",
    "    if min(layer_dims) < 1:\n",
    "          raise ValueError(\"The number of neurons in every layer must be at least 1\")\n",
    "    \n",
    "    if len(layer_dims) != len(activations) + 1:\n",
    "          raise ValueError(\n",
    "              f\"Structure Error: You provided {len(layer_dims)} layers but {len(activations)} activations. \"\n",
    "              f\"Expected {len(layer_dims) - 1} activations.\"\n",
    "          )\n",
    "\n",
    "    valid_activations = {\"relu\", \"sigmoid\", \"softmax\", \"linear\"}\n",
    "    for act in activations:\n",
    "        if act not in valid_activations:\n",
    "            raise ValueError(f\"Invalid activation '{act}'. Supported: {valid_activations}\")\n",
    "\n",
    "    valid_losses = {\"mse\", \"bce\", \"cce\"}\n",
    "    if loss_type not in valid_losses:\n",
    "        raise ValueError(f\"Invalid loss_type '{loss_type}'. Supported: {valid_losses}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a45327b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork(\n",
    "  activations=[\"relu\", \"relu\", \"relu\", \"sigmoid\"],\n",
    "  layer_dims=[3, 4, 2, 3, 2],\n",
    "  loss_type=\"mse\",\n",
    "  optimizer_type=\"adam\",\n",
    "  seed=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "49e955b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[ 1.46040903,  0.3564088 ,  0.07878985],\n",
       "        [-1.52153542, -0.22648652, -0.28965949],\n",
       "        [-0.06755814, -0.51194391, -0.03577739],\n",
       "        [-0.38964689, -1.07276608,  0.72229115]]),\n",
       " 'b1': array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]),\n",
       " 'W2': array([[ 0.62318596,  1.20885071,  0.03537913, -0.28615014],\n",
       "        [-0.38562772, -1.0935246 ,  0.69463867, -0.77857239]]),\n",
       " 'b2': array([[0.],\n",
       "        [0.]]),\n",
       " 'W3': array([[-1.18504653, -0.2056499 ],\n",
       "        [ 1.48614836,  0.23671627],\n",
       "        [-1.02378514, -0.7129932 ]]),\n",
       " 'b3': array([[0.],\n",
       "        [0.],\n",
       "        [0.]]),\n",
       " 'W4': array([[ 0.36098535, -0.09267243, -0.44388787],\n",
       "        [-0.1328083 ,  0.43015844,  1.14090809]]),\n",
       " 'b4': array([[0.],\n",
       "        [0.]])}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "30d188e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============== STARTING FORWARD PASS ===============\n",
      "Input Batch Shape: (3, 20) (20 examples)\n",
      "\n",
      "--- Layer 1 (RELU) ---\n",
      "Input Matrix (A_prev)     : (3, 20)\n",
      "Weight Matrix (W)         : (4, 3)\n",
      "Bias Vector (b)           : (4, 1) (Broadcasts automatically)\n",
      "---------------------------------------------\n",
      "Linear Step (Z = WA+b)    : (4, 20)\n",
      "Activation (A = f(Z))     : (4, 20)\n",
      "\n",
      "--- Layer 2 (RELU) ---\n",
      "Input Matrix (A_prev)     : (4, 20)\n",
      "Weight Matrix (W)         : (2, 4)\n",
      "Bias Vector (b)           : (2, 1) (Broadcasts automatically)\n",
      "---------------------------------------------\n",
      "Linear Step (Z = WA+b)    : (2, 20)\n",
      "Activation (A = f(Z))     : (2, 20)\n",
      "\n",
      "--- Layer 3 (RELU) ---\n",
      "Input Matrix (A_prev)     : (2, 20)\n",
      "Weight Matrix (W)         : (3, 2)\n",
      "Bias Vector (b)           : (3, 1) (Broadcasts automatically)\n",
      "---------------------------------------------\n",
      "Linear Step (Z = WA+b)    : (3, 20)\n",
      "Activation (A = f(Z))     : (3, 20)\n",
      "\n",
      "--- Layer 4 (SIGMOID) ---\n",
      "Input Matrix (A_prev)     : (3, 20)\n",
      "Weight Matrix (W)         : (2, 3)\n",
      "Bias Vector (b)           : (2, 1) (Broadcasts automatically)\n",
      "---------------------------------------------\n",
      "Linear Step (Z = WA+b)    : (2, 20)\n",
      "Activation (A = f(Z))     : (2, 20)\n",
      "\n",
      "=============== FORWARD PASS COMPLETE ==============\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = np.random.normal(size=(3, 20))\n",
    "\n",
    "y_pred = nn.forward_pass(X)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8e00ff42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.37234973, 0.91861426])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39558d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
